{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b709ab6",
   "metadata": {},
   "source": [
    "# 심층신경망\n",
    " ## - 케라스의 신경망 학습 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643ee60c",
   "metadata": {},
   "source": [
    "## 케라스(Keras), 텐서플로우 import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1dd82c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#keras.__version__\n",
    "#help(keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c9ccba",
   "metadata": {},
   "source": [
    "## 1) 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1cb0633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X, y_ori = iris.data , iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4df9f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 가공 \n",
    "# 클래스 정보 변환 - 원핫인코딩 \n",
    "\n",
    "#from sklearn.preprocessing import OneHOtEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y_ori, 3)\n",
    "\n",
    "#3 : class의 개수 (세토사,버지니카,버시컬러)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb2cf099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test , y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda5bf5e",
   "metadata": {},
   "source": [
    "## 2) 인공 신경망 모형 구성\n",
    "- Sequential()\n",
    "- Dense()\n",
    "- add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d1a9506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망을 어떻게 쌓을것인가\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#은닉층 생성\n",
    "model.add(Dense(units=8, input_dim=4, \n",
    "                kernel_initializer='uniform',\n",
    "                activation='relu'))\n",
    "\n",
    "#출력층 생성 \n",
    "model.add(Dense(units=3, \n",
    "                activation='softmax',\n",
    "                ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0a96786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#신경망 모델 제안(층을 이어서 타이핑한 순서대로 쌓음)\n",
    "#model.add : 두개의 층 쌓음\n",
    "\n",
    "#첫번째 층 : 노드개수 8개, 입력노드개수 4개(feature개수와 동일),relu함수 이용하여 활성화 \n",
    "\n",
    "#입력층 1, 은닉층 1, 출력층 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de0cefe",
   "metadata": {},
   "source": [
    "## 3) 모형의 학습 과정에 대한 설정\n",
    "- compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c89ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c47cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss : 손실함수 (다중 클래스 분류 교차 엔트로피)\n",
    "#optimizer : 경사하강법 - 가중치 최적화 알고리즘\n",
    "#metrics : 모델 성능 평가 지표 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb238b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d8cf13",
   "metadata": {},
   "source": [
    "## 4) 모형 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "594601e1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "105/105 - 27s - loss: 1.0418 - accuracy: 0.6286\n",
      "Epoch 2/100\n",
      "105/105 - 0s - loss: 0.9766 - accuracy: 0.6952\n",
      "Epoch 3/100\n",
      "105/105 - 0s - loss: 0.9071 - accuracy: 0.6952\n",
      "Epoch 4/100\n",
      "105/105 - 0s - loss: 0.8325 - accuracy: 0.6952\n",
      "Epoch 5/100\n",
      "105/105 - 0s - loss: 0.7674 - accuracy: 0.6952\n",
      "Epoch 6/100\n",
      "105/105 - 0s - loss: 0.7006 - accuracy: 0.6952\n",
      "Epoch 7/100\n",
      "105/105 - 0s - loss: 0.6480 - accuracy: 0.6952\n",
      "Epoch 8/100\n",
      "105/105 - 0s - loss: 0.6046 - accuracy: 0.6952\n",
      "Epoch 9/100\n",
      "105/105 - 0s - loss: 0.5610 - accuracy: 0.7048\n",
      "Epoch 10/100\n",
      "105/105 - 0s - loss: 0.5279 - accuracy: 0.7143\n",
      "Epoch 11/100\n",
      "105/105 - 0s - loss: 0.4994 - accuracy: 0.7619\n",
      "Epoch 12/100\n",
      "105/105 - 0s - loss: 0.4690 - accuracy: 0.7524\n",
      "Epoch 13/100\n",
      "105/105 - 0s - loss: 0.4473 - accuracy: 0.8286\n",
      "Epoch 14/100\n",
      "105/105 - 0s - loss: 0.4263 - accuracy: 0.8571\n",
      "Epoch 15/100\n",
      "105/105 - 0s - loss: 0.4057 - accuracy: 0.8762\n",
      "Epoch 16/100\n",
      "105/105 - 0s - loss: 0.3880 - accuracy: 0.8952\n",
      "Epoch 17/100\n",
      "105/105 - 0s - loss: 0.3737 - accuracy: 0.9524\n",
      "Epoch 18/100\n",
      "105/105 - 0s - loss: 0.3578 - accuracy: 0.9333\n",
      "Epoch 19/100\n",
      "105/105 - 0s - loss: 0.3444 - accuracy: 0.9333\n",
      "Epoch 20/100\n",
      "105/105 - 0s - loss: 0.3326 - accuracy: 0.9524\n",
      "Epoch 21/100\n",
      "105/105 - 0s - loss: 0.3216 - accuracy: 0.9619\n",
      "Epoch 22/100\n",
      "105/105 - 0s - loss: 0.3074 - accuracy: 0.9619\n",
      "Epoch 23/100\n",
      "105/105 - 0s - loss: 0.2972 - accuracy: 0.9619\n",
      "Epoch 24/100\n",
      "105/105 - 0s - loss: 0.2881 - accuracy: 0.9619\n",
      "Epoch 25/100\n",
      "105/105 - 0s - loss: 0.2750 - accuracy: 0.9619\n",
      "Epoch 26/100\n",
      "105/105 - 0s - loss: 0.2672 - accuracy: 0.9619\n",
      "Epoch 27/100\n",
      "105/105 - 0s - loss: 0.2603 - accuracy: 0.9619\n",
      "Epoch 28/100\n",
      "105/105 - 0s - loss: 0.2536 - accuracy: 0.9619\n",
      "Epoch 29/100\n",
      "105/105 - 0s - loss: 0.2454 - accuracy: 0.9619\n",
      "Epoch 30/100\n",
      "105/105 - 0s - loss: 0.2367 - accuracy: 0.9619\n",
      "Epoch 31/100\n",
      "105/105 - 0s - loss: 0.2282 - accuracy: 0.9619\n",
      "Epoch 32/100\n",
      "105/105 - 0s - loss: 0.2219 - accuracy: 0.9619\n",
      "Epoch 33/100\n",
      "105/105 - 0s - loss: 0.2174 - accuracy: 0.9714\n",
      "Epoch 34/100\n",
      "105/105 - 0s - loss: 0.2113 - accuracy: 0.9810\n",
      "Epoch 35/100\n",
      "105/105 - 0s - loss: 0.2041 - accuracy: 0.9619\n",
      "Epoch 36/100\n",
      "105/105 - 0s - loss: 0.2001 - accuracy: 0.9714\n",
      "Epoch 37/100\n",
      "105/105 - 0s - loss: 0.1936 - accuracy: 0.9714\n",
      "Epoch 38/100\n",
      "105/105 - 0s - loss: 0.1916 - accuracy: 0.9714\n",
      "Epoch 39/100\n",
      "105/105 - 0s - loss: 0.1832 - accuracy: 0.9619\n",
      "Epoch 40/100\n",
      "105/105 - 0s - loss: 0.1786 - accuracy: 0.9714\n",
      "Epoch 41/100\n",
      "105/105 - 0s - loss: 0.1780 - accuracy: 0.9714\n",
      "Epoch 42/100\n",
      "105/105 - 0s - loss: 0.1712 - accuracy: 0.9810\n",
      "Epoch 43/100\n",
      "105/105 - 0s - loss: 0.1653 - accuracy: 0.9714\n",
      "Epoch 44/100\n",
      "105/105 - 0s - loss: 0.1630 - accuracy: 0.9714\n",
      "Epoch 45/100\n",
      "105/105 - 0s - loss: 0.1615 - accuracy: 0.9619\n",
      "Epoch 46/100\n",
      "105/105 - 0s - loss: 0.1561 - accuracy: 0.9524\n",
      "Epoch 47/100\n",
      "105/105 - 0s - loss: 0.1512 - accuracy: 0.9714\n",
      "Epoch 48/100\n",
      "105/105 - 0s - loss: 0.1496 - accuracy: 0.9714\n",
      "Epoch 49/100\n",
      "105/105 - 0s - loss: 0.1445 - accuracy: 0.9714\n",
      "Epoch 50/100\n",
      "105/105 - 0s - loss: 0.1460 - accuracy: 0.9714\n",
      "Epoch 51/100\n",
      "105/105 - 0s - loss: 0.1385 - accuracy: 0.9714\n",
      "Epoch 52/100\n",
      "105/105 - 0s - loss: 0.1382 - accuracy: 0.9714\n",
      "Epoch 53/100\n",
      "105/105 - 0s - loss: 0.1380 - accuracy: 0.9619\n",
      "Epoch 54/100\n",
      "105/105 - 0s - loss: 0.1369 - accuracy: 0.9619\n",
      "Epoch 55/100\n",
      "105/105 - 0s - loss: 0.1323 - accuracy: 0.9714\n",
      "Epoch 56/100\n",
      "105/105 - 0s - loss: 0.1292 - accuracy: 0.9714\n",
      "Epoch 57/100\n",
      "105/105 - 0s - loss: 0.1259 - accuracy: 0.9714\n",
      "Epoch 58/100\n",
      "105/105 - 0s - loss: 0.1266 - accuracy: 0.9714\n",
      "Epoch 59/100\n",
      "105/105 - 0s - loss: 0.1237 - accuracy: 0.9714\n",
      "Epoch 60/100\n",
      "105/105 - 0s - loss: 0.1205 - accuracy: 0.9714\n",
      "Epoch 61/100\n",
      "105/105 - 0s - loss: 0.1191 - accuracy: 0.9714\n",
      "Epoch 62/100\n",
      "105/105 - 0s - loss: 0.1140 - accuracy: 0.9714\n",
      "Epoch 63/100\n",
      "105/105 - 0s - loss: 0.1167 - accuracy: 0.9714\n",
      "Epoch 64/100\n",
      "105/105 - 0s - loss: 0.1117 - accuracy: 0.9619\n",
      "Epoch 65/100\n",
      "105/105 - 0s - loss: 0.1129 - accuracy: 0.9524\n",
      "Epoch 66/100\n",
      "105/105 - 0s - loss: 0.1134 - accuracy: 0.9714\n",
      "Epoch 67/100\n",
      "105/105 - 0s - loss: 0.1133 - accuracy: 0.9619\n",
      "Epoch 68/100\n",
      "105/105 - 0s - loss: 0.1057 - accuracy: 0.9714\n",
      "Epoch 69/100\n",
      "105/105 - 0s - loss: 0.1067 - accuracy: 0.9619\n",
      "Epoch 70/100\n",
      "105/105 - 0s - loss: 0.1053 - accuracy: 0.9714\n",
      "Epoch 71/100\n",
      "105/105 - 0s - loss: 0.1060 - accuracy: 0.9714\n",
      "Epoch 72/100\n",
      "105/105 - 0s - loss: 0.1036 - accuracy: 0.9619\n",
      "Epoch 73/100\n",
      "105/105 - 0s - loss: 0.1009 - accuracy: 0.9714\n",
      "Epoch 74/100\n",
      "105/105 - 0s - loss: 0.1010 - accuracy: 0.9619\n",
      "Epoch 75/100\n",
      "105/105 - 0s - loss: 0.0989 - accuracy: 0.9714\n",
      "Epoch 76/100\n",
      "105/105 - 0s - loss: 0.1004 - accuracy: 0.9619\n",
      "Epoch 77/100\n",
      "105/105 - 0s - loss: 0.0958 - accuracy: 0.9714\n",
      "Epoch 78/100\n",
      "105/105 - 0s - loss: 0.0994 - accuracy: 0.9714\n",
      "Epoch 79/100\n",
      "105/105 - 0s - loss: 0.0973 - accuracy: 0.9714\n",
      "Epoch 80/100\n",
      "105/105 - 0s - loss: 0.0966 - accuracy: 0.9524\n",
      "Epoch 81/100\n",
      "105/105 - 0s - loss: 0.0950 - accuracy: 0.9714\n",
      "Epoch 82/100\n",
      "105/105 - 0s - loss: 0.0939 - accuracy: 0.9619\n",
      "Epoch 83/100\n",
      "105/105 - 0s - loss: 0.0948 - accuracy: 0.9619\n",
      "Epoch 84/100\n",
      "105/105 - 0s - loss: 0.0936 - accuracy: 0.9714\n",
      "Epoch 85/100\n",
      "105/105 - 0s - loss: 0.0870 - accuracy: 0.9714\n",
      "Epoch 86/100\n",
      "105/105 - 0s - loss: 0.0927 - accuracy: 0.9619\n",
      "Epoch 87/100\n",
      "105/105 - 0s - loss: 0.0867 - accuracy: 0.9714\n",
      "Epoch 88/100\n",
      "105/105 - 0s - loss: 0.0883 - accuracy: 0.9714\n",
      "Epoch 89/100\n",
      "105/105 - 0s - loss: 0.0871 - accuracy: 0.9714\n",
      "Epoch 90/100\n",
      "105/105 - 0s - loss: 0.0866 - accuracy: 0.9810\n",
      "Epoch 91/100\n",
      "105/105 - 0s - loss: 0.0838 - accuracy: 0.9714\n",
      "Epoch 92/100\n",
      "105/105 - 0s - loss: 0.0856 - accuracy: 0.9714\n",
      "Epoch 93/100\n",
      "105/105 - 0s - loss: 0.0849 - accuracy: 0.9714\n",
      "Epoch 94/100\n",
      "105/105 - 0s - loss: 0.0783 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "105/105 - 0s - loss: 0.0822 - accuracy: 0.9524\n",
      "Epoch 96/100\n",
      "105/105 - 0s - loss: 0.0831 - accuracy: 0.9619\n",
      "Epoch 97/100\n",
      "105/105 - 0s - loss: 0.0856 - accuracy: 0.9619\n",
      "Epoch 98/100\n",
      "105/105 - 0s - loss: 0.0793 - accuracy: 0.9714\n",
      "Epoch 99/100\n",
      "105/105 - 0s - loss: 0.0839 - accuracy: 0.9619\n",
      "Epoch 100/100\n",
      "105/105 - 0s - loss: 0.0785 - accuracy: 0.9905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13793832cd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "         epochs = 100,\n",
    "         batch_size = 1,\n",
    "         verbose=2)\n",
    "\n",
    "# epochs : 학습 반복 횟수\n",
    "# verbose : 학습 경과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4622b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(X_train, y_train , \n",
    "                epochs = 100,\n",
    "                batch_size = 1,\n",
    "                verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ba388c",
   "metadata": {},
   "source": [
    "train(학습) 데이터의 손실과 정확도 변화 확인\n",
    "- history 객체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c88cf001",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9714285731315613,\n",
       " 0.961904764175415,\n",
       " 0.9809523820877075,\n",
       " 0.961904764175415,\n",
       " 0.9809523820877075,\n",
       " 0.9714285731315613,\n",
       " 0.9904761910438538,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9809523820877075,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.961904764175415,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.961904764175415,\n",
       " 0.9714285731315613,\n",
       " 0.961904764175415,\n",
       " 0.961904764175415,\n",
       " 0.9714285731315613,\n",
       " 0.9809523820877075,\n",
       " 0.961904764175415,\n",
       " 0.9809523820877075,\n",
       " 0.9714285731315613,\n",
       " 0.9809523820877075,\n",
       " 0.9714285731315613,\n",
       " 0.961904764175415,\n",
       " 0.9714285731315613,\n",
       " 0.9809523820877075,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.961904764175415,\n",
       " 0.9809523820877075,\n",
       " 0.961904764175415,\n",
       " 0.9714285731315613,\n",
       " 0.961904764175415,\n",
       " 0.9809523820877075,\n",
       " 0.9809523820877075,\n",
       " 0.961904764175415,\n",
       " 0.9809523820877075,\n",
       " 0.9809523820877075,\n",
       " 0.961904764175415,\n",
       " 0.9714285731315613,\n",
       " 0.9809523820877075,\n",
       " 0.9714285731315613,\n",
       " 0.9904761910438538,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9904761910438538,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9809523820877075,\n",
       " 0.9809523820877075,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.961904764175415,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9809523820877075,\n",
       " 0.9714285731315613,\n",
       " 0.961904764175415,\n",
       " 0.9809523820877075,\n",
       " 0.9809523820877075,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9809523820877075,\n",
       " 0.9714285731315613,\n",
       " 0.9809523820877075,\n",
       " 0.9809523820877075,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9809523820877075,\n",
       " 0.9523809552192688,\n",
       " 0.9809523820877075,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9714285731315613,\n",
       " 0.9809523820877075,\n",
       " 0.961904764175415,\n",
       " 0.9714285731315613]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#훈련 정확도\n",
    "hist.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91a570e3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.07948096096515656,\n",
       " 0.0778311938047409,\n",
       " 0.07594924420118332,\n",
       " 0.08209751546382904,\n",
       " 0.07628172636032104,\n",
       " 0.07792388647794724,\n",
       " 0.07238038629293442,\n",
       " 0.07823333889245987,\n",
       " 0.07412980496883392,\n",
       " 0.07495829463005066,\n",
       " 0.07736793160438538,\n",
       " 0.07649248093366623,\n",
       " 0.07568293809890747,\n",
       " 0.07516101747751236,\n",
       " 0.07452449947595596,\n",
       " 0.07500141113996506,\n",
       " 0.07204537093639374,\n",
       " 0.071263387799263,\n",
       " 0.0711769387125969,\n",
       " 0.0727560967206955,\n",
       " 0.069392628967762,\n",
       " 0.07081976532936096,\n",
       " 0.07759395241737366,\n",
       " 0.06793425977230072,\n",
       " 0.07060353457927704,\n",
       " 0.06792043894529343,\n",
       " 0.06893393397331238,\n",
       " 0.06795452535152435,\n",
       " 0.06853438913822174,\n",
       " 0.0714881420135498,\n",
       " 0.07172758132219315,\n",
       " 0.06840348243713379,\n",
       " 0.06999237835407257,\n",
       " 0.07069151848554611,\n",
       " 0.06754697114229202,\n",
       " 0.06614790111780167,\n",
       " 0.06856333464384079,\n",
       " 0.06714353710412979,\n",
       " 0.0674428790807724,\n",
       " 0.06584446132183075,\n",
       " 0.06824846565723419,\n",
       " 0.06474430114030838,\n",
       " 0.06576034426689148,\n",
       " 0.06654603779315948,\n",
       " 0.06533176451921463,\n",
       " 0.06491338461637497,\n",
       " 0.06565867364406586,\n",
       " 0.06507556140422821,\n",
       " 0.06802241504192352,\n",
       " 0.06256705522537231,\n",
       " 0.06302886456251144,\n",
       " 0.06428638845682144,\n",
       " 0.06092922389507294,\n",
       " 0.06440643966197968,\n",
       " 0.060716815292835236,\n",
       " 0.06630124896764755,\n",
       " 0.06410682946443558,\n",
       " 0.06548740714788437,\n",
       " 0.06156465783715248,\n",
       " 0.06289810687303543,\n",
       " 0.06564471870660782,\n",
       " 0.06171274930238724,\n",
       " 0.06301852315664291,\n",
       " 0.0597221702337265,\n",
       " 0.059836309403181076,\n",
       " 0.061301931738853455,\n",
       " 0.06409111618995667,\n",
       " 0.06045801565051079,\n",
       " 0.06804071366786957,\n",
       " 0.060554154217243195,\n",
       " 0.06069732829928398,\n",
       " 0.061975497752428055,\n",
       " 0.05660136416554451,\n",
       " 0.06724745780229568,\n",
       " 0.0633830726146698,\n",
       " 0.061930909752845764,\n",
       " 0.056592781096696854,\n",
       " 0.05776023864746094,\n",
       " 0.060713622719049454,\n",
       " 0.05792803689837456,\n",
       " 0.0598754845559597,\n",
       " 0.05743887647986412,\n",
       " 0.059331007301807404,\n",
       " 0.059200551360845566,\n",
       " 0.05758146941661835,\n",
       " 0.06219088286161423,\n",
       " 0.061225373297929764,\n",
       " 0.05839787796139717,\n",
       " 0.05657273158431053,\n",
       " 0.05930955708026886,\n",
       " 0.058311544358730316,\n",
       " 0.06008799374103546,\n",
       " 0.05588679388165474,\n",
       " 0.05837061256170273,\n",
       " 0.0536358542740345,\n",
       " 0.05750018358230591,\n",
       " 0.057605694979429245,\n",
       " 0.06124396622180939,\n",
       " 0.05618802085518837,\n",
       " 0.05967292934656143]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#훈련 손실값\n",
    "hist.history['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4777c6f8",
   "metadata": {},
   "source": [
    "## 5) 모형의 성능 평가\n",
    "- evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd33e10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 9ms/step - loss: 0.0819 - accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "609c70a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "손실값: 0.082\n",
      "정확도: 0.978\n"
     ]
    }
   ],
   "source": [
    "#test 데이터의 손실과 정확도\n",
    "print(\"손실값:\",round(loss,3))\n",
    "print(\"정확도:\",round(acc,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d2c74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#주어진 데이터에 대해 과대적합이 아님\n",
    "#--> test데이터에서의 정확도가 train에서의 정확도보다 높게 나옴 \n",
    "#loss, acc = model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed288d4",
   "metadata": {},
   "source": [
    "## 6) 임의의 데이터에 대해 모형출력 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21f3fbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.39 4.43 0.51 0.01]\n",
      " [9.05 3.91 1.34 2.95]\n",
      " [5.15 1.49 5.35 8.76]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import random\n",
    "from numpy import round\n",
    "\n",
    "#임의 데이터 직접 생성\n",
    "X_new = round(random([3,4])*10, 2)\n",
    "print(X_new)\n",
    "\n",
    "#[3,4]: 3행 4열 배열을 만들기 \n",
    "#0이상 1 미만\n",
    "#4개 feature - 붓꽃\n",
    "#이데이터를 넣어서 확인해보는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70f86aca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00 3.7125456e-08 2.9198462e-27]\n",
      " [3.7114643e-02 9.6288532e-01 5.2520774e-09]\n",
      " [1.8200203e-35 2.3056643e-08 1.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_new)\n",
    "print(y_pred)\n",
    "\n",
    "#결과 - 한 라인이 하나의 데이터에 대한 추정된 확률(soft max 점수)\n",
    "\n",
    "#첫번째 붓꽃에서 0번레이블(클래스)일 확률 (8.3212894e-09)\n",
    "#첫번째 붓꽃은 2번 클래스 (확률이 제일 높음)\n",
    "\n",
    "#두번째 붓꽃 - 1번클래스 \n",
    "\n",
    "#3번째 - 2번클래스 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a20eba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "#클래스 정보\n",
    "y_pred_class = model.predict_classes(X_new)\n",
    "print(y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab3292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3c3443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
